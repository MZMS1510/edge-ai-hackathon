#!/usr/bin/env python3
"""
Qualcomm Edge AI Hub - Vers√£o Corrigida
Com fallback de c√¢mera e dados simulados como backup
"""

import os
import sys
import time
import threading
import numpy as np
import platform
import json
import cv2
import mediapipe as mp
from pathlib import Path
from flask import Flask, render_template, jsonify, request, Response
from flask_socketio import SocketIO, emit
import queue

# Adicionar diret√≥rio atual ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importar m√≥dulos locais
from utils.qualcomm_utils import QualcommUtils

app = Flask(__name__)
app.config['SECRET_KEY'] = 'qualcomm-edge-ai-hub-fixed'
socketio = SocketIO(app, cors_allowed_origins="*")

# Configura√ß√µes
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATES_DIR = os.path.join(SCRIPT_DIR, 'templates')

# Inst√¢ncias globais
coach_thread = None
is_coaching = False
camera_working = False

communication_metrics = {
    'posture_score': 0,
    'gesture_score': 0,
    'eye_contact_score': 0,
    'overall_score': 0,
    'feedback': []
}

# Configura√ß√µes de c√¢mera
CAMERA_CONFIG = {
    'width': 640,
    'height': 480,
    'fps': 30
}

def find_working_camera():
    """Encontra uma c√¢mera funcionando"""
    print("üîç Procurando c√¢mera funcionando...")
    
    for i in range(5):
        print(f"üé• Tentando c√¢mera {i}...")
        cap = cv2.VideoCapture(i)
        
        if cap.isOpened():
            # Tentar ler um frame
            ret, frame = cap.read()
            if ret:
                print(f"‚úÖ C√¢mera {i} funcionando!")
                cap.release()
                return i
            else:
                print(f"‚ùå C√¢mera {i} aberta mas n√£o l√™ frames")
                cap.release()
        else:
            print(f"‚ùå C√¢mera {i} n√£o dispon√≠vel")
    
    print("‚ùå Nenhuma c√¢mera funcionando")
    return None

@app.route('/')
def index():
    """P√°gina principal"""
    return render_template('communication_coach.html')

@app.route('/communication-coach')
def communication_coach_page():
    """P√°gina do coach de comunica√ß√£o"""
    return render_template('communication_coach.html')

@app.route('/status')
def status():
    """Status do sistema"""
    qualcomm_utils = QualcommUtils()
    system_info = qualcomm_utils.get_system_info()
    
    return jsonify({
        'snapdragon_detected': qualcomm_utils.snapdragon_detected,
        'system_info': system_info,
        'is_coaching': is_coaching,
        'camera_working': camera_working,
        'tools_available': qualcomm_utils.check_qualcomm_tools()
    })

# Rotas do Communication Coach
@app.route('/start_coaching')
def start_coaching():
    """Inicia an√°lise de comunica√ß√£o"""
    global coach_thread, is_coaching, camera_working
    
    if is_coaching:
        return jsonify({'error': 'An√°lise j√° est√° ativa'})
    
    try:
        print("üöÄ Iniciando an√°lise de comunica√ß√£o...")
        
        # Verificar c√¢mera
        camera_index = find_working_camera()
        if camera_index is None:
            print("‚ö†Ô∏è C√¢mera n√£o dispon√≠vel, usando dados simulados")
            camera_working = False
        else:
            camera_working = True
        
        # Iniciar thread de an√°lise
        is_coaching = True
        coach_thread = threading.Thread(target=coaching_loop, daemon=True, args=(camera_index,))
        coach_thread.start()
        
        print("‚úÖ Thread de coaching iniciada")
        return jsonify({'success': True, 'message': 'An√°lise iniciada'})
        
    except Exception as e:
        print(f"‚ùå Erro ao iniciar an√°lise: {e}")
        return jsonify({'error': f'Erro ao iniciar an√°lise: {str(e)}'})

@app.route('/stop_coaching')
def stop_coaching():
    """Para an√°lise de comunica√ß√£o"""
    global is_coaching
    
    if not is_coaching:
        return jsonify({'error': 'An√°lise n√£o est√° ativa'})
    
    try:
        print("ÔøΩÔøΩ Parando an√°lise de comunica√ß√£o...")
        is_coaching = False
        return jsonify({'success': True, 'message': 'An√°lise parada'})
        
    except Exception as e:
        return jsonify({'error': f'Erro ao parar an√°lise: {str(e)}'})

@app.route('/get_communication_metrics')
def get_communication_metrics():
    """Retorna m√©tricas de comunica√ß√£o"""
    return jsonify(communication_metrics)

def coaching_loop(camera_index=None):
    """Loop principal de an√°lise de comunica√ß√£o com fallback"""
    global communication_metrics, is_coaching, camera_working
    
    try:
        if camera_index is not None and camera_working:
            print("ÔøΩÔøΩ Usando c√¢mera real...")
            real_camera_loop(camera_index)
        else:
            print("ÔøΩÔøΩ Usando dados simulados...")
            simulated_loop()
            
    except Exception as e:
        print(f"‚ùå Erro no loop de coaching: {e}")
        # Fallback para dados simulados
        print("üîÑ Fallback para dados simulados...")
        simulated_loop()

def real_camera_loop(camera_index):
    """Loop com c√¢mera real"""
    global communication_metrics, is_coaching
    
    try:
        # Inicializar c√¢mera
        cap = cv2.VideoCapture(camera_index)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_CONFIG['width'])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_CONFIG['height'])
        cap.set(cv2.CAP_PROP_FPS, CAMERA_CONFIG['fps'])
        
        if not cap.isOpened():
            raise Exception("N√£o foi poss√≠vel abrir a c√¢mera")
        
        print("‚úÖ C√¢mera inicializada com sucesso")
        
        # Inicializar MediaPipe
        mp_pose = mp.solutions.pose
        mp_hands = mp.solutions.hands
        mp_face_mesh = mp.solutions.face_mesh
        
        with mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose, mp_hands.Hands(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as hands, mp_face_mesh.FaceMesh(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as face_mesh:
            
            print("‚úÖ MediaPipe inicializado")
            
            while is_coaching:
                try:
                    ret, frame = cap.read()
                    if not ret:
                        print("‚ùå Erro ao ler frame, tentando novamente...")
                        time.sleep(0.1)
                        continue
                    
                    # Processar frame
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    
                    # An√°lise real
                    pose_results = pose.process(rgb_frame)
                    posture_score = analyze_posture(pose_results)
                    
                    hands_results = hands.process(rgb_frame)
                    gesture_score = analyze_gestures(hands_results)
                    
                    face_results = face_mesh.process(rgb_frame)
                    eye_contact_score = analyze_eye_contact(frame, face_results)
                    
                    # Calcular score geral
                    overall_score = (posture_score + gesture_score + eye_contact_score) / 3
                    
                    # Gerar feedback
                    feedback = generate_feedback(posture_score, gesture_score, eye_contact_score)
                    
                    # Atualizar m√©tricas
                    communication_metrics.update({
                        'posture_score': posture_score,
                        'gesture_score': gesture_score,
                        'eye_contact_score': eye_contact_score,
                        'overall_score': overall_score,
                        'feedback': feedback
                    })
                    
                    # Enviar dados via WebSocket
                    socketio.emit('communication_data', communication_metrics)
                    
                    time.sleep(0.1)  # 100ms para 10 FPS
                    
                except Exception as e:
                    print(f"‚ùå Erro no processamento: {e}")
                    time.sleep(0.1)
                    
    except Exception as e:
        print(f"‚ùå Erro na c√¢mera real: {e}")
        raise e
    finally:
        try:
            cap.release()
        except:
            pass

def simulated_loop():
    """Loop com dados simulados"""
    global communication_metrics, is_coaching
    
    print("üé≠ Iniciando dados simulados...")
    
    while is_coaching:
        try:
            # Gerar dados simulados realistas
            posture_score = np.random.normal(75, 15)
            posture_score = max(0, min(100, posture_score))
            
            gesture_score = np.random.normal(70, 20)
            gesture_score = max(0, min(100, gesture_score))
            
            eye_contact_score = np.random.normal(80, 10)
            eye_contact_score = max(0, min(100, eye_contact_score))
            
            overall_score = (posture_score + gesture_score + eye_contact_score) / 3
            
            # Gerar feedback
            feedback = generate_feedback(posture_score, gesture_score, eye_contact_score)
            
            # Atualizar m√©tricas
            communication_metrics.update({
                'posture_score': posture_score,
                'gesture_score': gesture_score,
                'eye_contact_score': eye_contact_score,
                'overall_score': overall_score,
                'feedback': feedback
            })
            
            # Enviar dados via WebSocket
            socketio.emit('communication_data', communication_metrics)
            
            print(f"üìä Simulado: Postura={posture_score:.1f}, Gestos={gesture_score:.1f}, Olhos={eye_contact_score:.1f}")
            
            time.sleep(1)  # 1 segundo
            
        except Exception as e:
            print(f"‚ùå Erro nos dados simulados: {e}")
            time.sleep(1)

def analyze_posture(pose_results):
    """Analisa postura usando MediaPipe Pose"""
    if not pose_results.pose_landmarks:
        return 50
    
    landmarks = pose_results.pose_landmarks.landmark
    
    try:
        # Pontos de refer√™ncia para postura
        nose = landmarks[mp_pose.PoseLandmark.NOSE]
        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]
        right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]
        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]
        right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]
        
        # Calcular alinhamento dos ombros
        shoulder_angle = abs(left_shoulder.y - right_shoulder.y)
        hip_angle = abs(left_hip.y - right_hip.y)
        
        # Calcular postura ereta
        spine_alignment = abs((left_shoulder.y + right_shoulder.y) / 2 - 
                            (left_hip.y + right_hip.y) / 2)
        
        # Score baseado no alinhamento
        shoulder_score = max(0, 100 - shoulder_angle * 200)
        hip_score = max(0, 100 - hip_angle * 200)
        spine_score = max(0, 100 - spine_alignment * 100)
        
        return (shoulder_score + hip_score + spine_score) / 3
        
    except Exception as e:
        print(f"Erro na an√°lise de postura: {e}")
        return 50

def analyze_gestures(hands_results):
    """Analisa gestos usando MediaPipe Hands"""
    if not hands_results.multi_hand_landmarks:
        return 30
    
    try:
        gesture_score = 0
        hand_count = len(hands_results.multi_hand_landmarks)
        
        for hand_landmarks in hands_results.multi_hand_landmarks:
            # Analisar posi√ß√£o das m√£os
            wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]
            
            # Calcular movimento das m√£os
            hand_movement = abs(wrist.y - thumb_tip.y) + abs(wrist.y - index_tip.y)
            
            # Score baseado no movimento
            if hand_movement > 0.1:
                gesture_score += 50
            elif hand_movement > 0.05:
                gesture_score += 30
            else:
                gesture_score += 10
        
        return min(100, gesture_score / hand_count) if hand_count > 0 else 30
        
    except Exception as e:
        print(f"Erro na an√°lise de gestos: {e}")
        return 30

def analyze_eye_contact(frame, face_results):
    """Analisa contato visual usando MediaPipe Face Mesh"""
    if not face_results.multi_face_landmarks:
        return 40
    
    try:
        # Pontos dos olhos
        left_eye = face_results.multi_face_landmarks[0].landmark[33]
        right_eye = face_results.multi_face_landmarks[0].landmark[133]
        
        # Calcular posi√ß√£o dos olhos em rela√ß√£o ao centro da tela
        frame_height, frame_width = frame.shape[:2]
        center_x = frame_width / 2
        center_y = frame_height / 2
        
        eye_center_x = (left_eye.x + right_eye.x) / 2 * frame_width
        eye_center_y = (left_eye.y + right_eye.y) / 2 * frame_height
        
        # Dist√¢ncia do centro
        distance_from_center = np.sqrt((eye_center_x - center_x)**2 + (eye_center_y - center_y)**2)
        
        # Score baseado na proximidade do centro
        max_distance = np.sqrt(center_x**2 + center_y**2)
        eye_contact_score = max(0, 100 - (distance_from_center / max_distance) * 100)
        
        return eye_contact_score
        
    except Exception as e:
        print(f"Erro na an√°lise de contato visual: {e}")
        return 40

def generate_feedback(posture_score, gesture_score, eye_contact_score):
    """Gera feedback personalizado"""
    feedback = []
    
    # Feedback de postura
    if posture_score < 50:
        feedback.append("ÔøΩÔøΩ Mantenha a postura ereta - alinhe os ombros")
    elif posture_score < 75:
        feedback.append("üü° Melhore o alinhamento dos ombros")
    else:
        feedback.append("üü¢ Postura excelente!")
    
    # Feedback de gestos
    if gesture_score < 30:
        feedback.append("üî¥ Use mais gestos com as m√£os para expressividade")
    elif gesture_score < 60:
        feedback.append("üü° Varie seus gestos para maior impacto")
    else:
        feedback.append("üü¢ Gestos muito expressivos!")
    
    # Feedback de contato visual
    if eye_contact_score < 50:
        feedback.append("üî¥ Olhe mais para a c√¢mera - mantenha contato visual")
    elif eye_contact_score < 75:
        feedback.append("üü° Mantenha contato visual consistente")
    else:
        feedback.append("üü¢ Contato visual perfeito!")
    
    return feedback

# WebSocket events
@socketio.on('connect')
def handle_connect():
    """Cliente conectado"""
    print("üîå Cliente conectado via WebSocket")
    emit('status', {'message': 'Conectado ao Communication Coach'})

@socketio.on('disconnect')
def handle_disconnect():
    """Cliente desconectado"""
    print("üîå Cliente desconectado")

if __name__ == '__main__':
    print("üöÄ Iniciando Communication Coach (Vers√£o Corrigida)...")
    print("üìç Acesse: http://localhost:5000")
    socketio.run(app, host='0.0.0.0', port=5000, debug=True)
