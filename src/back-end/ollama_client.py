import requests
import json
import time
from typing import Dict, Any, Optional

class OllamaClient:
    def __init__(self, base_url="http://localhost:11434", model="deepseek-r1:8b"):
        self.base_url = base_url
        self.model = model
        self.api_url = f"{base_url}/api/generate"
    
    def test_connection(self):
        """Testa conex√£o com Ollama"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def generate_response(self, prompt: str, max_tokens: int = 500, temperature: float = 0.7):
        """Gera resposta usando DeepSeek-R1"""
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": temperature,
                "num_predict": max_tokens,
                "top_p": 0.9
            }
        }
        
        try:
            response = requests.post(
                self.api_url, 
                json=payload, 
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "Erro na resposta")
            else:
                return f"Erro HTTP: {response.status_code}"
                
        except requests.exceptions.Timeout:
            return "‚ùå Timeout - DeepSeek demorou muito para responder"
        except requests.exceptions.ConnectionError:
            return "‚ùå Conex√£o falhou - Verifique se Ollama est√° rodando"
        except Exception as e:
            return f"‚ùå Erro: {str(e)}"
    
    def analyze_presentation(self, transcript: str, metrics: Optional[Dict] = None):
        """An√°lise espec√≠fica para apresenta√ß√µes usando DeepSeek-R1"""
        
        # Preparar contexto com m√©tricas se dispon√≠vel
        metrics_context = ""
        if metrics:
            nervousness = metrics.get('nervousness_score', 0)
            blink_rate = metrics.get('blink_stats', {}).get('blink_rate', 0)
            hand_movement = metrics.get('raw_metrics', {}).get('avg_hand_movement', 0)
            
            metrics_context = f"""
M√©tricas de nervosismo detectadas:
- Score de nervosismo: {nervousness:.2f}/1.0
- Taxa de piscadas: {blink_rate:.2f}
- Movimento das m√£os: {hand_movement:.3f}
"""
        
        prompt = f"""Voc√™ √© um coach especialista em apresenta√ß√µes. Analise esta apresenta√ß√£o e forne√ßa feedback construtivo.

TRANSCRI√á√ÉO DA APRESENTA√á√ÉO:
"{transcript}"

{metrics_context}

INSTRU√á√ïES:
1. Analise o conte√∫do, linguagem e estrutura da apresenta√ß√£o
2. Se houver m√©tricas de nervosismo, considere-as na an√°lise
3. D√™ exatamente 3 dicas pr√°ticas e espec√≠ficas de melhoria
4. Seja direto, construtivo e motivador
5. Responda em portugu√™s brasileiro

FORMATO DA RESPOSTA:
üéØ **DICA 1**: [t√≠tulo]
[explica√ß√£o pr√°tica de 1-2 linhas]

üéØ **DICA 2**: [t√≠tulo]  
[explica√ß√£o pr√°tica de 1-2 linhas]

üéØ **DICA 3**: [t√≠tulo]
[explica√ß√£o pr√°tica de 1-2 linhas]

üí° **PONTO POSITIVO**: [algo que est√° funcionando bem]
"""

        return self.generate_response(prompt, max_tokens=400, temperature=0.8)
    
    def analyze_transcript_only(self, transcript: str):
        """An√°lise r√°pida apenas do texto"""
        if not transcript or len(transcript.strip()) < 10:
            return "‚ùå Transcri√ß√£o muito curta para an√°lise. Fale mais sobre o tema!"
        
        prompt = f"""Analise esta fala de apresenta√ß√£o e d√™ 3 dicas r√°pidas:

TEXTO: "{transcript}"

Responda em formato simples:
1. [dica sobre conte√∫do]
2. [dica sobre linguagem] 
3. [dica sobre estrutura]

Seja direto e pr√°tico."""

        return self.generate_response(prompt, max_tokens=200, temperature=0.7)
    
    def get_topic_suggestions(self, transcript: str):
        """Sugere t√≥picos baseado na transcri√ß√£o"""
        prompt = f"""Com base nesta fala: "{transcript}"

Sugira 3 t√≥picos relacionados que a pessoa poderia abordar para enriquecer a apresenta√ß√£o:

1. [t√≥pico 1]
2. [t√≥pico 2] 
3. [t√≥pico 3]

Seja espec√≠fico e relevante ao contexto."""

        return self.generate_response(prompt, max_tokens=150)

# Inst√¢ncia global
ollama_client = OllamaClient()

def get_coaching_feedback(transcript: str, metrics: Optional[Dict] = None):
    """Fun√ß√£o de conveni√™ncia para an√°lise completa"""
    if not ollama_client.test_connection():
        return "‚ùå Ollama n√£o est√° rodando. Execute: ollama serve"
    
    return ollama_client.analyze_presentation(transcript, metrics)

def quick_text_analysis(transcript: str):
    """An√°lise r√°pida apenas do texto"""
    if not ollama_client.test_connection():
        return "‚ùå Ollama offline"
    
    return ollama_client.analyze_transcript_only(transcript)