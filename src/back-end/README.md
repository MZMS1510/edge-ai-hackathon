# Edge Coach - Analista de ApresentaÃ§Ãµes com IA (100% Local)

Sistema completo de anÃ¡lise de apresentaÃ§Ãµes executando inteiramente em dispositivos edge. Utiliza MediaPipe para anÃ¡lise visual, processamento de Ã¡udio para transcriÃ§Ã£o, e IA local (Ollama) para feedback inteligente.

## ğŸ“‘ Ãndice

- [ğŸ¯ CaracterÃ­sticas](#-caracterÃ­sticas)
- [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto) 
- [ğŸš€ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ğŸ”§ ExecuÃ§Ã£o](#-execuÃ§Ã£o)
- [ğŸ“¡ API Reference](#-api-reference)
- [ğŸ”Œ WebSocket Protocol](#-websocket-protocol)
- [ğŸ§  Componentes de IA](#-componentes-de-ia)
- [ğŸ§ª Testes](#-testes)
- [ğŸ“Š MÃ©tricas](#-mÃ©tricas)
- [ğŸ› ï¸ Ferramentas AvanÃ§adas](#ï¸-ferramentas-avanÃ§adas)
- [ğŸš¨ SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)
- [ğŸ“ Desenvolvimento](#-desenvolvimento)
- [ğŸ“‹ Changelog](#-changelog)

## ğŸ¯ CaracterÃ­sticas

- **100% Local**: Nenhum dado sai do dispositivo
- **AnÃ¡lise em Tempo Real**: WebSocket para processamento contÃ­nuo
- **IA Integrada**: Feedback inteligente via Ollama (DeepSeek-R1)
- **VisÃ£o Computacional**: MediaPipe para detecÃ§Ã£o de poses, gestos e expressÃµes
- **AnÃ¡lise de Ãudio**: DetecÃ§Ã£o de vÃ­cios de linguagem e mÃ©tricas vocais
- **APIs REST**: Interface completa para integraÃ§Ã£o
- **Dashboard Interativo**: Interface Streamlit para visualizaÃ§Ã£o

## ğŸ“ Estrutura do Projeto

### Arquivos Principais
```
â”œâ”€â”€ main.py                    # Servidor FastAPI principal (REST API)
â”œâ”€â”€ websocket_server.py        # Servidor WebSocket para tempo real
â”œâ”€â”€ core_processing.py         # Processamento MediaPipe e extraÃ§Ã£o de features
â”œâ”€â”€ ollama_client.py          # Cliente para IA local (Ollama)
â”œâ”€â”€ pose_model.py             # ClassificaÃ§Ã£o de poses corporais
â”œâ”€â”€ version.py                # InformaÃ§Ãµes de versÃ£o
â””â”€â”€ requirements_minimal.txt   # DependÃªncias essenciais
```

### UtilitÃ¡rios
```
â”œâ”€â”€ ui_streamlit.py           # Dashboard Streamlit
â”œâ”€â”€ capture_audio.py          # Captura de Ã¡udio standalone
â”œâ”€â”€ capture_video.py          # Captura de vÃ­deo standalone
â”œâ”€â”€ train_pose_model.py       # Treinamento de modelos de pose
â””â”€â”€ test_websocket.py         # Testes WebSocket
```

### Ferramentas AvanÃ§adas
```
tools/
â”œâ”€â”€ extract_keypoints_mediapipe.py  # ExtraÃ§Ã£o de landmarks
â”œâ”€â”€ pose_inference_batch.py         # InferÃªncia em lote
â””â”€â”€ run_pipeline_example.py         # Pipeline completo
```

## ğŸš€ InstalaÃ§Ã£o

### 1. Ambiente Python
```bash
cd src/back-end
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### 2. DependÃªncias
```bash
# InstalaÃ§Ã£o mÃ­nima (recomendada)
pip install -r requirements_minimal.txt

# Ou instalaÃ§Ã£o completa
pip install -r requirements.txt
```

### 3. ConfiguraÃ§Ã£o Ollama (Opcional)
```bash
# Instalar Ollama: https://ollama.com/download
ollama serve
ollama pull deepseek-r1:8b

# Configurar URL (padrÃ£o jÃ¡ Ã© localhost)
export OLLAMA_URL="http://localhost:11434/api/generate"
```

## ğŸ”§ ExecuÃ§Ã£o

### OpÃ§Ã£o 1: Servidor REST API
```bash
# MÃ©todo 1: Direto
python main.py

# MÃ©todo 2: Via uvicorn
uvicorn main:app --host 0.0.0.0 --port 8000
```
ğŸŒ **Acesso**: http://localhost:8000  
ğŸ“– **DocumentaÃ§Ã£o**: http://localhost:8000/docs

### OpÃ§Ã£o 2: Servidor WebSocket (Tempo Real)
```bash
python websocket_server.py
```
ğŸ”Œ **WebSocket**: ws://localhost:8765  
ğŸ§ª **Teste**: Acesse via browser para cliente HTML integrado

### OpÃ§Ã£o 3: Dashboard Streamlit
```bash
streamlit run ui_streamlit.py
```
ğŸ“Š **Dashboard**: http://localhost:8501

### OpÃ§Ã£o 4: ExecuÃ§Ã£o Completa (Recomendada)
Execute simultaneamente para funcionalidade completa:
```bash
# Terminal 1: API REST
python main.py

# Terminal 2: WebSocket
python websocket_server.py

# Terminal 3: Dashboard (opcional)
streamlit run ui_streamlit.py
```

## ğŸ“¡ API Reference

### REST API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | Server info |
| `GET` | `/health` | Health check |
| `GET` | `/docs` | API documentation |
| `POST` | `/metrics` | Send video metrics |
| `POST` | `/transcript` | Send audio transcript |
| `POST` | `/analyze` | Analyze text for filler words |
| `POST` | `/pose-classify` | Classify body pose |
| `GET` | `/stats` | Current session stats |
| `GET` | `/metrics?count=N` | Get metrics history |
| `GET` | `/transcript` | Get full transcript |
| `GET` | `/analysis` | Get available analyses |
| `POST` | `/analysis/generate` | Force new analysis |
| `POST` | `/reset` | Reset session |

### Exemplos de Uso

#### AnÃ¡lise de Texto
```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"text":"EntÃ£o, tipo, hoje vou falar sobre IA, nÃ©?"}'

# Resposta
{
  "summary": "Detectados 3 vÃ­cios de linguagem",
  "repetitions": [
    {"phrase": "tipo", "count": 1, "examples": ["..."]}
  ],
  "suggestions": ["Evite repetiÃ§Ãµes..."]
}
```

#### MÃ©tricas de VÃ­deo
```bash
curl -X POST http://localhost:8000/metrics \
  -H "Content-Type: application/json" \
  -d '{
    "timestamp": 1693486200.0,
    "nervousness_score": 0.3,
    "blink_detected": true,
    "blink_stats": {"blink_rate": 15.2},
    "hand_movement": 0.45,
    "head_movement": 0.23,
    "hands_detected": 2,
    "face_detected": 1,
    "raw_metrics": {"avg_hand_movement": 0.45}
  }'
```

#### ClassificaÃ§Ã£o de Poses
```bash
curl -X POST http://localhost:8000/pose-classify \
  -H "Content-Type: application/json" \
  -d '{
    "joints": {
      "nose_x": 0.5, "nose_y": 0.3,
      "left_shoulder_x": 0.4, "left_shoulder_y": 0.4
    }
  }'

# Resposta
{
  "label": "good",
  "score": 0.85
}
```

## ğŸ”Œ WebSocket Protocol

### Tipos de Mensagem

| Type | Direction | Description |
|------|-----------|-------------|
| `video_frame` | Client â†’ Server | Send video frame for analysis |
| `audio_data` | Client â†’ Server | Send audio data |
| `transcript` | Client â†’ Server | Send transcript text |
| `get_stats` | Client â†’ Server | Request session statistics |
| `reset_session` | Client â†’ Server | Reset session data |
| `ping` | Client â†’ Server | Ping/pong for connection test |
| `video_analysis` | Server â†’ Client | Video analysis results |
| `audio_analysis` | Server â†’ Client | Audio analysis results |
| `session_stats` | Server â†’ Client | Session statistics |
| `error` | Server â†’ Client | Error message |

### Exemplo JavaScript
```javascript
// Conectar ao WebSocket
const ws = new WebSocket('ws://localhost:8765');

// Enviar frame de vÃ­deo
ws.send(JSON.stringify({
  type: 'video_frame',
  frame: base64_encoded_frame
}));

// Receber anÃ¡lise
ws.onmessage = function(event) {
  const data = JSON.parse(event.data);
  if (data.type === 'video_analysis') {
    console.log('Nervousness:', data.metrics.nervousness_score);
  }
};
```

## ğŸ§  Componentes de IA

### MediaPipe Processing
- **DetecÃ§Ã£o de Poses**: 33 pontos corporais
- **Malha Facial**: 468 landmarks faciais  
- **DetecÃ§Ã£o de MÃ£os**: AtÃ© 2 mÃ£os simultaneamente
- **MÃ©tricas AutomÃ¡ticas**: Nervosismo, piscadas, movimento

### AnÃ¡lise de Ãudio
- **Processamento em Tempo Real**: Chunks de 1024 samples
- **ExtraÃ§Ã£o de Features**: Volume, zero-crossings, energia
- **Buffer Circular**: MantÃ©m 5 segundos de histÃ³rico

### IA Local (Ollama)
- **Modelo PadrÃ£o**: DeepSeek-R1:8b
- **AnÃ¡lise Contextual**: Combina mÃ©tricas visuais e texto
- **Feedback Personalizado**: Dicas especÃ­ficas em portuguÃªs
- **Fallback Local**: Funciona sem Ollama

## ğŸ§ª Testes

### Teste de Endpoints
```bash
# Teste bÃ¡sico do servidor
python -c "
import requests
response = requests.get('http://localhost:8000/')
print(response.json())
"

# Teste de anÃ¡lise
python -c "
import requests
response = requests.post('http://localhost:8000/analyze', 
    json={'text': 'Tipo, entÃ£o, nÃ©...'})
print(response.json())
"
```

### Teste WebSocket
```bash
python test_websocket.py
```

### VerificaÃ§Ã£o de DependÃªncias
```bash
python -c "
import mediapipe as mp
import cv2
import numpy as np
print('âœ… Todas as dependÃªncias OK')
"
```

### Suite de Testes
```bash
cd tests
python -m pytest -v
```

## ğŸ“Š MÃ©tricas

### MÃ©tricas Visuais
- **Nervosismo**: Score 0-1 baseado em movimento e piscadas
- **Taxa de Piscadas**: Piscadas por minuto (normal: 12-20)
- **Movimento das MÃ£os**: Amplitude de gestos
- **Movimento da CabeÃ§a**: Estabilidade postural
- **DetecÃ§Ãµes**: Contagem de faces/mÃ£os detectadas

### MÃ©tricas de Ãudio
- **Volume**: RMS do sinal
- **Zero Crossings**: Indicador de vocalizaÃ§Ã£o
- **Energia**: PotÃªncia do sinal

### AnÃ¡lise de Texto
- **VÃ­cios de Linguagem**: "tipo", "nÃ©", "entÃ£o", "basicamente", etc.
- **RepetiÃ§Ãµes**: Frases/palavras recorrentes
- **SugestÃµes**: RecomendaÃ§Ãµes automÃ¡ticas

### CÃ¡lculo do Score de Nervosismo
```python
# Fatores considerados:
blink_nervousness = (blink_rate - 12) / 20  # Normal: 12-20/min
hand_nervousness = hand_movement * 10       # Normalizado
head_nervousness = head_movement * 5        # Normalizado

nervousness_score = mean([blink_nervousness, hand_nervousness, head_nervousness])
nervousness_score = clamp(nervousness_score, 0, 1)
```

## ğŸ› ï¸ Ferramentas AvanÃ§adas

### ExtraÃ§Ã£o de Keypoints
```bash
# Extrair landmarks de vÃ­deo
python tools/extract_keypoints_mediapipe.py \
  --video input.mp4 \
  --out keypoints.csv \
  --frame-step 2
```

### Treinamento de Modelo de Pose
```bash
# Treinar classificador personalizado
python train_pose_model.py \
  --csv labeled_data.csv \
  --out pose_model.joblib
```

### InferÃªncia em Lote
```bash
# Processar CSV de keypoints
python tools/pose_inference_batch.py \
  --csv keypoints.csv \
  --model pose_model.joblib \
  --out results.json
```

### Pipeline Completo
```bash
# Executar pipeline completo
python tools/run_pipeline_example.py \
  --video presentation.mp4 \
  --outdir ./analysis_results
```

## ğŸš¨ SoluÃ§Ã£o de Problemas

### Erros Comuns

#### "Module not found"
```bash
pip install -r requirements_minimal.txt
```

#### "Ollama connection failed"
```bash
# Verificar se Ollama estÃ¡ rodando
curl http://localhost:11434/api/tags

# Iniciar Ollama
ollama serve
```

#### "Camera not found"
```bash
# Verificar cÃ¢meras disponÃ­veis
python -c "
import cv2
for i in range(3):
    cap = cv2.VideoCapture(i)
    if cap.isOpened():
        print(f'Camera {i}: OK')
    cap.release()
"
```

#### "Port already in use"
```bash
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill
```

#### Performance Issues
- Reduza a taxa de quadros: `frame_step=2` ou mais
- Use `model_complexity=0` no MediaPipe
- Diminua resoluÃ§Ã£o do vÃ­deo se necessÃ¡rio
- Monitore uso de CPU/memÃ³ria

## ğŸ“ Desenvolvimento

### Estrutura de Classes

#### MediaPipeProcessor
```python
from core_processing import MediaPipeProcessor

processor = MediaPipeProcessor()
results = processor.process_frame(frame)
# Returns: metrics, joints, landmarks, annotated_frame
```

#### FeatureTracker
```python
from core_processing import FeatureTracker

tracker = FeatureTracker(window_size=30)
metrics = tracker.extract_metrics(face, pose, hands)
# Returns: nervousness_score, blink_stats, movements
```

#### OllamaClient
```python
from ollama_client import OllamaClient

client = OllamaClient()
feedback = client.analyze_presentation(transcript, metrics)
# Returns: AI-generated coaching feedback
```

### Adicionando Novos Endpoints
```python
@app.post("/meu-endpoint")
async def meu_endpoint(data: MeuModel):
    # Sua lÃ³gica aqui
    return {"resultado": "sucesso"}
```

### ConfiguraÃ§Ã£o AvanÃ§ada
```bash
# VariÃ¡veis de ambiente
export OLLAMA_URL="http://localhost:11434/api/generate"
export OLLAMA_MODEL="deepseek-r1:8b"
export LOG_LEVEL="DEBUG"
```

### Logs e Debug
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Em main.py
logger = logging.getLogger(__name__)
logger.debug("Debug message")
```

## ğŸ“‹ Changelog

### Version 2.0.0 - Consolidated Architecture (2025-08-31)

#### ğŸš€ Major Changes
- **Consolidated Architecture**: Reduced from 20+ files to 6 core files
- **Unified Processing**: All MediaPipe logic consolidated
- **Single WebSocket Server**: Combined multiple implementations
- **Improved Documentation**: Comprehensive single README

#### âœ¨ New Features
- **Real-time WebSocket Processing**: Live video/audio analysis
- **Enhanced AI Integration**: Better Ollama client with fallbacks
- **Session Management**: Complete session lifecycle handling
- **Multi-client Support**: WebSocket broadcasting
- **Built-in Test Client**: HTML interface for testing

#### ğŸ“ File Structure Changes
**Consolidated Files:**
- `core_processing.py` â† `features.py` + `media_pipe_utils.py` + `analyze.py`
- `websocket_server.py` â† Multiple server implementations

**Core Files Enhanced:**
- `main.py` - Better error handling and validation
- `ollama_client.py` - Connection testing and fallbacks
- `pose_model.py` - Improved heuristics

#### ğŸ”§ API Changes
**New Endpoints:**
- `POST /transcript` - Handle audio transcriptions
- `GET /analysis` - Get available analyses
- `POST /analysis/generate` - Force analysis generation
- `POST /reset` - Reset session data

#### ğŸ“‹ Dependencies
- **Minimal Requirements**: Essential packages only
- **Better Error Handling**: Graceful fallbacks
- **Improved Imports**: Relative/absolute handling

### Future Roadmap

#### Version 2.1.0 (Planned)
- [ ] Enhanced AI models integration
- [ ] Real-time collaboration features
- [ ] Mobile app support
- [ ] Cloud deployment options

#### Version 2.2.0 (Planned)
- [ ] Multi-language support
- [ ] Advanced analytics dashboard
- [ ] Custom model training pipeline
- [ ] Performance optimizations

## ğŸ¤ Contribuindo

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. FaÃ§a commit das mudanÃ§as (`git commit -am 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

### Guidelines de Desenvolvimento
- Mantenha operaÃ§Ã£o 100% local
- Documente todas as funÃ§Ãµes pÃºblicas
- Adicione testes para novas funcionalidades
- Siga padrÃµes de cÃ³digo Python (PEP 8)
- Use type hints quando possÃ­vel

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte do Edge AI Hackathon e segue as diretrizes de uso local e privacidade.

**Edge Coach v2.0.0** - Sistema de AnÃ¡lise de ApresentaÃ§Ãµes com IA  
Desenvolvido pela equipe Edge AI Hackathon Team  
Build: 2025-08-31
